[project]
name = "spark_streaming"
version = "0.1.0"
description = "Spark Streaming jobs for Bronze layer ingestion"
requires-python = ">=3.11"

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = ["--strict-markers", "-ra"]
markers = [
    "integration: marks tests as integration tests (require Docker services)",
]

[tool.mypy]
python_version = "3.11"
warn_unused_configs = true
check_untyped_defs = true
warn_redundant_casts = true
exclude = ["venv/", "tests/"]
explicit_package_bases = true
files = ["config", "framework", "jobs", "utils"]

# pyspark and delta have no type stubs available
[[tool.mypy.overrides]]
module = ["pyspark", "pyspark.*", "delta", "delta.*"]
ignore_missing_imports = true

# spark_streaming imports use absolute paths that resolve in Docker
# but not locally (directory is spark-streaming, not spark_streaming)
[[tool.mypy.overrides]]
module = ["spark_streaming", "spark_streaming.*"]
ignore_missing_imports = true
