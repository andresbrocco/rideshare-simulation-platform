apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-thrift-server
  labels:
    app: spark-thrift-server
spec:
  replicas: 1
  selector:
    matchLabels:
      app: spark-thrift-server
  template:
    metadata:
      labels:
        app: spark-thrift-server
    spec:
      initContainers:
      - name: wait-for-hive-metastore
        image: busybox:1.36
        command:
        - sh
        - -c
        - |
          until nc -z hive-metastore 9083; do
            echo "Waiting for Hive Metastore..."
            sleep 5
          done
          echo "Hive Metastore is ready"
      - name: wait-for-minio
        image: busybox:1.36
        command:
        - sh
        - -c
        - |
          until nc -z minio 9000; do
            echo "Waiting for MinIO..."
            sleep 2
          done
          echo "MinIO is ready"
      - name: wait-for-openldap
        image: busybox:1.36
        command:
        - sh
        - -c
        - |
          until nc -z openldap 389; do
            echo "Waiting for OpenLDAP..."
            sleep 2
          done
          echo "OpenLDAP is ready"
      containers:
      - name: spark-thrift-server
        image: apache/spark:4.0.0-python3
        imagePullPolicy: Never
        command:
        - /opt/spark/bin/spark-submit
        - --master
        - local[2]
        - --driver-memory
        - 1800m
        - --conf
        - spark.driver.memoryOverhead=512m
        - --conf
        - spark.driver.maxResultSize=512m
        - --conf
        - spark.driver.extraJavaOptions=-XX:+UseG1GC -XX:MaxGCPauseMillis=50 -XX:InitiatingHeapOccupancyPercent=35 -XX:+ExplicitGCInvokesConcurrent
        - --conf
        - spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension
        - --conf
        - spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog
        - --conf
        - spark.sql.warehouse.dir=s3a://rideshare-bronze/warehouse
        - --conf
        - spark.hadoop.hive.metastore.uris=thrift://hive-metastore:9083
        - --conf
        - spark.hadoop.fs.s3a.endpoint=http://minio:9000
        - --conf
        - spark.hadoop.fs.s3a.access.key=$(MINIO_ROOT_USER)
        - --conf
        - spark.hadoop.fs.s3a.secret.key=$(MINIO_ROOT_PASSWORD)
        - --conf
        - spark.hadoop.fs.s3a.path.style.access=true
        - --conf
        - spark.hadoop.fs.s3a.connection.ssl.enabled=false
        - --conf
        - spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
        - --conf
        - spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
        - --conf
        - spark.hadoop.fs.s3a.threads.max=8
        - --conf
        - spark.hadoop.fs.s3a.connection.pool.size=8
        - --conf
        - spark.hadoop.fs.s3a.connection.establish.timeout=5000
        - --conf
        - spark.hadoop.fs.s3a.connection.timeout=200000
        - --conf
        - spark.ui.retainedStages=100
        - --conf
        - spark.ui.retainedJobs=100
        - --conf
        - spark.ui.retainedDeadExecutors=10
        - --conf
        - spark.sql.codegen.cache.maxEntries=100
        - --class
        - org.apache.spark.sql.hive.thriftserver.HiveThriftServer2
        - --name
        - Thrift JDBC/ODBC Server
        - --hiveconf
        - hive.metastore.warehouse.dir=s3a://rideshare-bronze/warehouse
        - --hiveconf
        - hive.server2.thrift.port=10000
        - --hiveconf
        - hive.server2.thrift.bind.host=0.0.0.0
        - --hiveconf
        - hive.server2.authentication=LDAP
        - --hiveconf
        - hive.server2.authentication.ldap.url=ldap://openldap:389
        - --hiveconf
        - hive.server2.authentication.ldap.baseDN=dc=rideshare,dc=local
        - --hiveconf
        - hive.server2.transport.mode=binary
        - --hiveconf
        - hive.server2.thrift.min.worker.threads=4
        - --hiveconf
        - hive.server2.thrift.max.worker.threads=16
        resources:
          limits:
            memory: "3072Mi"
          requests:
            memory: "1024Mi"
            cpu: "250m"
        ports:
        - containerPort: 10000
          name: thrift
        - containerPort: 4040
          name: ui
        env:
        - name: MINIO_ROOT_USER
          valueFrom:
            secretKeyRef:
              name: app-credentials
              key: MINIO_ROOT_USER
        - name: MINIO_ROOT_PASSWORD
          valueFrom:
            secretKeyRef:
              name: app-credentials
              key: MINIO_ROOT_PASSWORD
        - name: LDAP_USERNAME
          valueFrom:
            secretKeyRef:
              name: app-credentials
              key: HIVE_LDAP_USERNAME
        - name: LDAP_PASSWORD
          valueFrom:
            secretKeyRef:
              name: app-credentials
              key: HIVE_LDAP_PASSWORD
        - name: PYTHONPATH
          value: /opt
        livenessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - /opt/spark/bin/beeline -u 'jdbc:hive2://localhost:10000/default' -n ${LDAP_USERNAME} -p ${LDAP_PASSWORD} -e 'SELECT 1' --silent=true
          initialDelaySeconds: 90
          periodSeconds: 15
          timeoutSeconds: 10
          failureThreshold: 10
        readinessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - /opt/spark/bin/beeline -u 'jdbc:hive2://localhost:10000/default' -n ${LDAP_USERNAME} -p ${LDAP_PASSWORD} -e 'SELECT 1' --silent=true
          initialDelaySeconds: 60
          periodSeconds: 10
          timeoutSeconds: 10

---
apiVersion: v1
kind: Service
metadata:
  name: spark-thrift-server
  labels:
    app: spark-thrift-server
spec:
  type: ClusterIP
  ports:
  - port: 10000
    targetPort: 10000
    name: thrift
  - port: 4040
    targetPort: 4040
    name: ui
  selector:
    app: spark-thrift-server
