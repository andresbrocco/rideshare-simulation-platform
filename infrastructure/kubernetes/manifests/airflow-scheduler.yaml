apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-scheduler
  labels:
    app: airflow-scheduler
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow-scheduler
  template:
    metadata:
      labels:
        app: airflow-scheduler
    spec:
      initContainers:
      - name: wait-for-webserver
        image: busybox:1.36
        command:
        - sh
        - -c
        - |
          until wget -qO- http://airflow-webserver:8082/api/v2/monitor/health 2>/dev/null | grep -q '"status"'; do
            echo "Waiting for Airflow API server to be healthy..."
            sleep 5
          done
          echo "Airflow API server is ready"
      containers:
      - name: airflow-scheduler
        image: apache/airflow:3.1.5
        command:
        - bash
        - -c
        - airflow dags reserialize && exec airflow scheduler
        resources:
          limits:
            memory: "2048Mi"
          requests:
            memory: "512Mi"
        env:
        - name: AIRFLOW_POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: app-credentials
              key: AIRFLOW_POSTGRES_PASSWORD
        - name: AIRFLOW__CORE__FERNET_KEY
          valueFrom:
            secretKeyRef:
              name: app-credentials
              key: FERNET_KEY
        - name: AIRFLOW__API_AUTH__JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: app-credentials
              key: AIRFLOW_JWT_SECRET
        - name: AIRFLOW__CORE__EXECUTOR
          value: LocalExecutor
        - name: AIRFLOW__DATABASE__SQL_ALCHEMY_CONN
          value: "postgresql+psycopg2://airflow:$(AIRFLOW_POSTGRES_PASSWORD)@airflow-postgres/airflow"
        - name: AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION
          value: "false"
        - name: AIRFLOW__CORE__LOAD_EXAMPLES
          value: "false"
        - name: AIRFLOW__CORE__AUTH_MANAGER
          value: airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager
        - name: AIRFLOW__CORE__PARALLELISM
          value: "8"
        - name: AIRFLOW__DAG_PROCESSOR__REFRESH_INTERVAL
          value: "30"
        - name: AIRFLOW__CORE__EXECUTION_API_SERVER_URL
          value: "http://airflow-webserver:8082/execution/"
        - name: DBT_SPARK_HOST
          value: spark-thrift-server
        - name: AWS_ENDPOINT_URL
          value: "http://minio:9000"
        - name: AWS_ALLOW_HTTP
          value: "true"
        - name: AWS_REGION
          value: "us-east-1"
        - name: _PIP_ADDITIONAL_REQUIREMENTS
          value: apache-airflow-providers-fab dbt-core dbt-duckdb==1.10.0 dbt-spark[PyHive] duckdb==1.4.4 deltalake==1.4.2 duckdb-engine==0.17.0 great-expectations requests prison
        livenessProbe:
          tcpSocket:
            port: 8793
          initialDelaySeconds: 60
          periodSeconds: 10
          timeoutSeconds: 10
        readinessProbe:
          tcpSocket:
            port: 8793
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 10
        volumeMounts:
        - name: dags
          mountPath: /opt/airflow/dags/dbt_transformation_dag.py
          subPath: dbt_transformation_dag.py
        - name: dags
          mountPath: /opt/airflow/dags/delta_maintenance_dag.py
          subPath: delta_maintenance_dag.py
        - name: dags
          mountPath: /opt/airflow/dags/dlq_monitoring_dag.py
          subPath: dlq_monitoring_dag.py
        - name: logs
          mountPath: /opt/airflow/logs
      volumes:
      - name: dags
        configMap:
          name: airflow-dags
      - name: logs
        emptyDir: {}
