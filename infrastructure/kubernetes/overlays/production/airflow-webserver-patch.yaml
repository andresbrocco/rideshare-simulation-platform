# Production patch: Point Airflow Webserver to RDS and configure subdomain routing
# - Overrides init container to check RDS instead of local airflow-postgres
# - Overrides SQL_ALCHEMY_CONN to use RDS endpoint
# - Removes AWS_ENDPOINT_URL (was for MinIO; production uses real AWS S3)
# - Sets AWS_REGION for S3 access via IRSA
# - Configures AIRFLOW__WEBSERVER__BASE_URL for subdomain routing
#
# Replace <rds-endpoint> with Terraform output during deploy:
#   terraform -chdir=infrastructure/terraform/platform output -raw rds_endpoint
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-webserver
spec:
  template:
    spec:
      initContainers:
        - name: wait-for-postgres
          image: busybox:1.36
          command:
            - sh
            - -c
            - |
              until nc -z <rds-endpoint> 5432; do
                echo "Waiting for RDS PostgreSQL..."
                sleep 2
              done
              echo "RDS PostgreSQL is ready"
      containers:
        - name: airflow-webserver
          command:
            - bash
            - -c
            - |
              pip install --quiet --no-cache-dir apache-airflow-providers-amazon

              # URL-encode the password so special chars don't break the conn string
              ENCODED_PW=$(python3 -c "import urllib.parse; print(urllib.parse.quote('${AIRFLOW_POSTGRES_PASSWORD}'))")
              export AIRFLOW__DATABASE__SQL_ALCHEMY_CONN="postgresql+psycopg2://airflow:${ENCODED_PW}@<rds-endpoint>:5432/airflow"
              airflow db migrate
              airflow users create --username admin --password "${AIRFLOW_ADMIN_PASSWORD}" \
                --firstname Admin --lastname User --role Admin --email admin@example.com || true
              exec airflow api-server
          env:
            - name: AIRFLOW_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: app-credentials
                  key: AIRFLOW_POSTGRES_PASSWORD

            # Remove MinIO endpoint override (use real AWS S3)
            - name: AWS_ENDPOINT_URL
              $patch: delete

            # Ensure AWS region is set for IRSA-based S3 access
            - name: AWS_REGION
              value: "us-east-1"

            # Configure base URL for subdomain routing
            - name: AIRFLOW__WEBSERVER__BASE_URL
              value: "https://airflow.ridesharing.portfolio.andresbrocco.com"

            # Remote logging to S3 (logs readable in Airflow UI and via aws s3 cp)
            - name: AIRFLOW__LOGGING__REMOTE_LOGGING
              value: "True"
            - name: AIRFLOW__LOGGING__REMOTE_BASE_LOG_FOLDER
              value: "s3://rideshare-<account-id>-logs/airflow"
            - name: AIRFLOW__LOGGING__REMOTE_LOG_CONN_ID
              value: "aws_default"
            - name: AIRFLOW_CONN_AWS_DEFAULT
              value: "aws://?region_name=us-east-1"
