# =============================================================================
# SECRETS MANAGEMENT
# =============================================================================
#
# This project uses LocalStack Secrets Manager for credential management.
# Credentials are NOT stored in .env files.
#
# How it works:
# 1. The secrets-init service runs on Docker Compose startup
# 2. It seeds LocalStack Secrets Manager with generated credentials
# 3. It fetches secrets and writes them to /secrets volume as .env files
# 4. Services source credentials from /secrets/*.env files at startup
#
# Secrets are organized into three files on the secrets volume:
# - /secrets/core.env          → KAFKA_SASL_*, REDIS_PASSWORD, API_KEY, SCHEMA_REGISTRY_*
# - /secrets/data-pipeline.env → MINIO_ROOT_*, POSTGRES_*, AIRFLOW_*, LDAP_*
# - /secrets/monitoring.env    → GRAFANA_ADMIN_PASSWORD
#
# To start services with secrets:
#   docker compose -f infrastructure/docker/compose.yml --profile core up -d
#
# The secrets-init service automatically runs before other services start.
# No manual credential configuration is required for local development.
#
# =============================================================================


# =============================================================================
# SIMULATION CONFIGURATION
# =============================================================================

# Speed multiplier: 1 (real-time), 10 (10x faster), or 100 (100x faster)
SIM_SPEED_MULTIPLIER=1

# Logging level: DEBUG, INFO, WARNING, ERROR
SIM_LOG_LEVEL=INFO

# Checkpoint interval in simulated seconds (minimum 60)
SIM_CHECKPOINT_INTERVAL=300


# =============================================================================
# KAFKA (CONFLUENT CLOUD)
# =============================================================================
# NOTE: For production with Confluent Cloud, set these values.
# For local Docker development, credentials are managed via secrets-init.

# Comma-separated list of Confluent Cloud bootstrap servers
# Example: pkc-xxxxx.us-east-1.aws.confluent.cloud:9092
KAFKA_BOOTSTRAP_SERVERS=

# Security protocol (use SASL_SSL for Confluent Cloud)
KAFKA_SECURITY_PROTOCOL=SASL_SSL

# SASL mechanism (use PLAIN for Confluent Cloud)
KAFKA_SASL_MECHANISMS=PLAIN

# Confluent Cloud credentials - injected from /secrets/core.env in Docker
# KAFKA_SASL_USERNAME (set via secrets-init)
# KAFKA_SASL_PASSWORD (set via secrets-init)

# Schema Registry endpoint
# Example: https://psrc-xxxxx.us-east-2.aws.confluent.cloud
KAFKA_SCHEMA_REGISTRY_URL=

# Schema Registry credentials - injected from /secrets/core.env in Docker
# KAFKA_SCHEMA_REGISTRY_BASIC_AUTH_USER_INFO (set via secrets-init)


# =============================================================================
# REDIS (ELASTICACHE)
# =============================================================================
# NOTE: For production with ElastiCache, set hostname and enable SSL.
# For local Docker development, credentials are managed via secrets-init.

# Redis hostname
# Local: localhost
# ElastiCache: your-cluster.xxxxx.use1.cache.amazonaws.com
REDIS_HOST=localhost

# Redis port (default: 6379)
REDIS_PORT=6379

# Redis password - injected from /secrets/core.env in Docker
# REDIS_PASSWORD (set via secrets-init)

# Enable SSL/TLS (true for ElastiCache, false for local)
REDIS_SSL=false


# =============================================================================
# OSRM (ROUTING SERVICE)
# =============================================================================

# OSRM service base URL (no trailing slash)
# Local: http://localhost:5000
# AWS ECS: http://osrm-service.internal:5000
OSRM_BASE_URL=http://localhost:5000


# =============================================================================
# AWS
# =============================================================================

# AWS region for LocalStack and boto3
AWS_REGION=us-east-1


# =============================================================================
# CONTROL PANEL API
# =============================================================================

# API key - injected from /secrets/core.env in Docker
# API_KEY (set via secrets-init)
# For production: generate with `openssl rand -hex 32`

# CORS origins (comma-separated)
CORS_ORIGINS=http://localhost:5173,http://localhost:3000


# =============================================================================
# CONTROL PANEL FRONTEND
# =============================================================================

# Backend API URL (used by frontend to make API calls)
VITE_API_URL=http://localhost:8000

# WebSocket URL for real-time updates
VITE_WS_URL=ws://localhost:8000/ws


# =============================================================================
# STREAM PROCESSOR
# =============================================================================

# Window size for GPS aggregation (in milliseconds)
# Smaller = more responsive, larger = more reduction
# Default: 100 (10 updates/sec max per entity)
PROCESSOR_WINDOW_SIZE_MS=100

# Aggregation strategy: "latest" or "sample"
# - latest: Keep only the most recent GPS ping per entity per window
# - sample: Keep every Nth message (controlled by PROCESSOR_SAMPLE_RATE)
PROCESSOR_AGGREGATION_STRATEGY=latest

# For "sample" strategy: emit every Nth message
PROCESSOR_SAMPLE_RATE=10

# Logging level for stream processor
PROCESSOR_LOG_LEVEL=INFO


# =============================================================================
# DOCKER COMPOSE (LOCAL DEVELOPMENT)
# =============================================================================
# These settings are automatically used when running with docker compose.
# Override any setting above by creating a .env.local file (gitignored).
#
# Secrets Management:
# - All credentials are managed by the secrets-init service
# - Services automatically source credentials from /secrets/*.env files
# - No manual credential configuration needed
#
# For local Docker development, these services connect via container names:
# - kafka:29092 (internal Kafka port)
# - redis:6379
# - osrm:5000
# - stream-processor (consumes from Kafka, publishes to Redis)
#
# When running outside Docker, use localhost with exposed ports:
# - localhost:9092 (Kafka)
# - localhost:6379 (Redis)
# - localhost:5000 (OSRM)
